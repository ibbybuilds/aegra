"""Opportunity Discovery Service.

This service discovers events and job opportunities for users based on:
1. Their currently enrolled courses/tracks
2. Their current location

It uses Brave Search API to find relevant opportunities and scores them for relevance.
"""

from datetime import UTC, datetime, timedelta
from decimal import Decimal
from typing import Any

import httpx
import structlog
from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession

from src.agent_server.core.accountability_orm import (
    DiscoveredOpportunity,
    Notification,
    UserPreferences,
)
from src.agent_server.settings import settings

logger = structlog.get_logger()


# Track keyword mapping for search queries
TRACK_KEYWORDS: dict[str, list[str]] = {
    "data-analytics": [
        "data analytics",
        "SQL",
        "Power BI",
        "Tableau",
        "Excel",
        "business intelligence",
        "BI analyst",
        "data analyst",
    ],
    "data-science": [
        "data science",
        "machine learning",
        "Python",
        "ML engineer",
        "data scientist",
        "statistics",
        "predictive analytics",
    ],
    "data-engineering": [
        "data engineering",
        "ETL",
        "Spark",
        "Airflow",
        "data pipeline",
        "data engineer",
        "dbt",
        "Snowflake",
    ],
    "ai-engineering": [
        "AI engineer",
        "LLM",
        "GenAI",
        "artificial intelligence",
        "prompt engineering",
        "ML Ops",
        "deep learning",
    ],
    "business-intelligence": [
        "business intelligence",
        "BI developer",
        "reporting",
        "dashboards",
        "Power BI",
        "Looker",
        "Business Intelligence",
    ],
}


class OpportunityDiscoveryEngine:
    """Discovers relevant opportunities (events, jobs) for users."""

    def __init__(self, brave_api_key: str | None = None):
        self.brave_api_key = brave_api_key or settings.app.BRAVE_API_KEY
        self.lms_base_url = settings.app.LMS_URL

    async def get_user_enrollments(self, user_id: str, auth_token: str) -> list[dict]:
        """Fetch user's enrolled courses/tracks from LMS API."""
        """Fetch user's enrolled courses/tracks from LMS API."""
        if not self.lms_base_url:
            logger.warning("LMS API URL not configured")
            return []

        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.lms_base_url}/api/v1/enrollment/student/blackboard",
                    headers={"Authorization": f"Bearer {auth_token}"},
                    timeout=10.0,
                )
                response.raise_for_status()
                data = response.json()
                enrollments = data.get("enrollments", [])
                
                # Extract track names for logging
                track_names = []
                for e in enrollments:
                    course = e.get("course", {})
                    name = course.get("title") or course.get("track") or e.get("trackName")
                    track_names.append(name)
                    
                logger.info(f"Fetched {len(enrollments)} enrollments from LMS", user_id=user_id, tracks=track_names)
                return enrollments
        except httpx.HTTPError as e:
            logger.error("Failed to fetch enrollments", error=str(e), user_id=user_id)
            return []

    async def get_user_location(
        self, session: AsyncSession, user_id: str
    ) -> str | None:
        """Get user's location from preferences."""
        result = await session.execute(
            select(UserPreferences).where(UserPreferences.user_id == user_id)
        )
        prefs = result.scalar_one_or_none()
        return prefs.location if prefs else None

    def build_event_queries(self, track: str, location: str) -> list[str]:
        """Generate location + track specific event search queries."""
        track_key = track.lower().replace(" ", "-")
        keywords = TRACK_KEYWORDS.get(track_key, [track.lower()])

        queries = []
        # Limit to top 3 keywords to avoid too many API calls
        for kw in keywords[:3]:
            # Targeted LinkedIn and general event sites
            queries.append(f"site:linkedin.com/events {kw} {location}")
            queries.append(f"{kw} meetup {location}")
            queries.append(f"{kw} hackathon {location} 2026")

        return queries

    def build_job_queries(self, track: str, location: str) -> list[str]:
        """Generate location + track specific job search queries."""
        track_key = track.lower().replace(" ", "-")
        keywords = TRACK_KEYWORDS.get(track_key, [track.lower()])

        queries = []
        # Use broader job search queries since LinkedIn blocks search engine indexing
        # Target job boards and general job search terms
        for kw in keywords[:2]:
            queries.append(f"{kw} job {location} junior")
            queries.append(f"{kw} job {location} entry level")
            queries.append(f"{kw} internship {location}")
            queries.append(f"hiring {kw} {location}")

        return queries

    async def brave_search(self, query: str, freshness: str = "pw") -> list[dict[str, Any]]:
        """Execute a Brave Search API query.
        
        Args:
            query: Search query
            freshness: Time range filter ('pd' for past day, 'pw' for past week, 'pm' for past month)
        """
        if not self.brave_api_key:
            logger.warning("Brave API key not configured")
            return []

        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    "https://api.search.brave.com/res/v1/web/search",
                    headers={
                        "Accept": "application/json",
                        "X-Subscription-Token": self.brave_api_key,
                    },
                    params={
                        "q": query,
                        "count": 5,
                        "freshness": freshness,
                    },
                    timeout=10.0,
                )
                response.raise_for_status()
                data = response.json()
                return data.get("web", {}).get("results", [])
        except httpx.HTTPError as e:
            logger.error("Brave search failed", error=str(e), query=query)
            return []

    def parse_event_result(
        self, result: dict[str, Any], track: str, location: str
    ) -> dict[str, Any] | None:
        """Parse a search result into an event opportunity."""
        title = result.get("title", "")
        description = result.get("description", "")
        url = result.get("url", "")

        # Basic relevance check - must mention something event-like
        event_keywords = ["meetup", "event", "workshop", "conference", "webinar", "summit"]
        if not any(kw in title.lower() or kw in description.lower() for kw in event_keywords):
            return None

        return {
            "opportunity_type": "event",
            "title": title,
            "description": description,
            "url": url,
            "location": location,
            "matched_track": track,
            "match_score": self.calculate_match_score(result, track),
        }

    def parse_job_result(
        self, result: dict[str, Any], track: str, location: str
    ) -> dict[str, Any] | None:
        """Parse a search result into a job opportunity."""
        title = result.get("title", "")
        description = result.get("description", "")
        url = result.get("url", "")
        
        is_linkedin = "linkedin.com/jobs" in url

        # Basic relevance check - must look like a job
        # Skip this check for LinkedIn as we explicitly searched for jobs there
        if not is_linkedin:
            job_keywords = ["job", "career", "hiring", "position", "role", "apply"]
            if not any(kw in title.lower() or kw in description.lower() for kw in job_keywords):
                return None

        # Try to extract company from title
        company = None
        
        # Clean up LinkedIn titles
        # Format often: "Job Title at Company | LinkedIn" or "Job Title - Location - Company"
        clean_title = title.replace(" | LinkedIn", "").replace(" | LinkedIn - Job", "")
        
        if " at " in clean_title:
            # "Data Scientist at Google" -> company = Google
            parts = clean_title.split(" at ")
            if len(parts) > 1:
                company = parts[-1].split(" - ")[0].strip()
        elif "-" in clean_title:
             # "Data Scientist - Google" -> company = Google
            parts = clean_title.split("-")
            # Usually the last part or second to last is company if location is included
            # Heuristic: if 3 parts, middle might be company or location. 
            # Let's just take the part after the first dash?
            if len(parts) > 1:
                potential_company = parts[-1].strip()
                # If specifically LinkedIn format "Role - Company - Location"
                if len(parts) >= 3 and is_linkedin:
                     potential_company = parts[1].strip()
                company = potential_company

        return {
            "opportunity_type": "job",
            "title": clean_title,
            "description": description,
            "url": url,
            "location": location,
            "company": company,
            "matched_track": track,
            "match_score": self.calculate_match_score(result, track),
        }

    def calculate_match_score(self, result: dict[str, Any], track: str) -> Decimal:
        """Calculate a relevance score for the result (0.00 - 1.00)."""
        score = 0.5  # Base score

        title = result.get("title", "").lower()
        description = result.get("description", "").lower()
        content = title + " " + description

        track_key = track.lower().replace(" ", "-")
        keywords = TRACK_KEYWORDS.get(track_key, [track.lower()])

        # Increase score for each matching keyword
        for kw in keywords:
            if kw.lower() in content:
                score += 0.1

        # Cap at 1.0
        return Decimal(str(min(score, 1.0)))

    async def discover_for_user(
        self,
        session: AsyncSession,
        user_id: str,
        auth_token: str,
    ) -> list[DiscoveredOpportunity]:
        """Discover opportunities for a specific user."""
        # Get user's enrolled tracks
        enrollments = await self.get_user_enrollments(user_id, auth_token)
        if not enrollments:
            logger.info("No enrollments found", user_id=user_id)
            return []

        # Get user's location
        location = await self.get_user_location(session, user_id)
        if not location:
            logger.info("No location set for user", user_id=user_id)
            # Use a default or skip
            location = "remote"  # Default to remote opportunities

        discovered = []
        seen_urls: set[str] = set()

        for enrollment in enrollments:
            # Handle nested course object from LMS
            course = enrollment.get("course", {})
            track_name = course.get("title") or course.get("track") or enrollment.get("trackName", "")
            
            if not track_name:
                continue

            # Search for events
            event_queries = self.build_event_queries(track_name, location)
            logger.info(f"Generated event queries for {track_name}", queries=event_queries)
            
            for query in event_queries[:2]:  # Limit queries
                results = await self.brave_search(query)
                logger.info(f"Brave search results for '{query}'", count=len(results))
                
                for result in results:
                    url = result.get("url", "")
                    if url in seen_urls:
                        continue
                    seen_urls.add(url)

                    event = self.parse_event_result(result, track_name, location)
                    if event:
                        opp = DiscoveredOpportunity(
                            user_id=user_id,
                            opportunity_type=event["opportunity_type"],
                            title=event["title"],
                            description=event["description"],
                            url=event["url"],
                            location=event["location"],
                            matched_track=event["matched_track"],
                            match_score=event["match_score"],
                            expires_at=datetime.now(UTC) + timedelta(days=30),
                            metadata_json={"source": "brave_search", "query": query},
                        )
                        session.add(opp)
                        discovered.append(opp)

            # Search for jobs
            job_queries = self.build_job_queries(track_name, location)
            logger.info(f"Generated job queries for {track_name}", queries=job_queries)
            
            for query in job_queries[:2]:  # Limit queries
                results = await self.brave_search(query)
                logger.info(f"Brave job search results for '{query}'", count=len(results))
                
                for result in results:
                    url = result.get("url", "")
                    logger.debug(f"Processing job result: {url}")
                    
                    if url in seen_urls:
                        logger.debug(f"Skipping duplicate URL: {url}")
                        continue
                    seen_urls.add(url)

                    job = self.parse_job_result(result, track_name, location)
                    if job:
                        logger.info(f"Found job: {job['title']}", url=url)
                        opp = DiscoveredOpportunity(
                            user_id=user_id,
                            opportunity_type=job["opportunity_type"],
                            title=job["title"],
                            description=job["description"],
                            url=job["url"],
                            location=job["location"],
                            company=job.get("company"),
                            matched_track=job["matched_track"],
                            match_score=job["match_score"],
                            expires_at=datetime.now(UTC) + timedelta(days=14),
                            metadata_json={"source": "brave_search", "query": query},
                        )
                        session.add(opp)
                        discovered.append(opp)
                    else:
                        logger.debug(f"Job result filtered out: {result.get('title', 'no title')}")

        await session.commit()

        logger.info(
            "opportunities_discovered",
            user_id=user_id,
            count=len(discovered),
            events=len([o for o in discovered if o.opportunity_type == "event"]),
            jobs=len([o for o in discovered if o.opportunity_type == "job"]),
        )

        return discovered

    async def create_opportunity_notification(
        self,
        session: AsyncSession,
        opportunity: DiscoveredOpportunity,
    ) -> Notification:
        """Create a notification for a discovered opportunity."""
        if opportunity.opportunity_type == "event":
            title = "ðŸŽ¯ New Event Matches Your Track"
            content = f"We found an event that matches your {opportunity.matched_track} learning path: {opportunity.title}"
            action_buttons = [
                {"action": "view", "title": "View Event", "url": opportunity.url},
                {"action": "dismiss", "title": "Not Interested"},
            ]
        else:
            title = "ðŸ’¼ Job Opportunity Alert"
            content = f"New {opportunity.matched_track} role: {opportunity.title}"
            if opportunity.company:
                content += f" at {opportunity.company}"
            action_buttons = [
                {"action": "view", "title": "View Job", "url": opportunity.url},
                {"action": "dismiss", "title": "Not Interested"},
            ]

        notification = Notification(
            user_id=opportunity.user_id,
            title=title,
            content=content,
            channel="in_app",
            priority="normal",
            category="opportunity",
            action_buttons=action_buttons,
            metadata_json={
                "opportunity_id": opportunity.id,
                "opportunity_type": opportunity.opportunity_type,
            },
            expires_at=opportunity.expires_at,
        )
        session.add(notification)

        # Update opportunity status
        opportunity.status = "notified"

        await session.commit()
        return notification


# Singleton instance
opportunity_engine = OpportunityDiscoveryEngine()
